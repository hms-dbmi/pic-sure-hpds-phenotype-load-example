{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the PIC-SURE-HPDS client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#!{sys.executable} -m pip uninstall git+https://github.com/hms-dbmi/pic-sure-python-client.git    \n",
    "#!{sys.executable} -m pip uninstall git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install git+https://github.com/hms-dbmi/pic-sure-python-client.git    \n",
    "!{sys.executable} -m pip install git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect directly to the HPDS resource, bypassing all security. This should never be possible in an instance holding private data. \n",
    "\n",
    "# An HPDS instance should always be hosted behind a PIC-SURE API and PIC-SURE Auth Micro-App instance if it has any privacy concern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import pandas\n",
    "import PicSureHpdsLib\n",
    "adapter = PicSureHpdsLib.BypassAdapter(\"http://pic-sure-hpds-nhanes:8080/PIC-SURE\")\n",
    "resource = adapter.useResource()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dictionary = resource.dictionary().find()\n",
    "all_concepts = data_dictionary.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See how many concepts were loaded in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_concepts.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the expected counts and ranges for each of your variables. This will require comparing these values to your source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sorted_concepts = all_concepts.sort_index(axis = 0)\n",
    "sorted_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because the source file is sorted by CONCEPT_PATH and PATIENT_NUM it is fairly straight forward to confirm that the rows match. First we retrieve all concepts for all patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = resource.query()\n",
    "query.select().add(data_dictionary.keys())\n",
    "all_concepts_dataframe = query.getResultsDataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We unpivot the data back into a single line per patient and concept like the original file sorted in the same order as the original file for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melted = pandas.melt(all_concepts_dataframe, col_level=0, id_vars=['Patient ID'])\n",
    "loaded_data = melted.sort_values(by=['variable', 'Patient ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We then load the original source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_data = pandas.read_csv('allConcepts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... and join the NVAL_NUM and TVAL_CHAR entries on our loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_data = pandas.merge(original_data, loaded_data, left_on=['PATIENT_NUM','CONCEPT_PATH'], right_on=['Patient ID','variable']).drop(columns=['Patient ID', 'variable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can see here that most of the data seems ok, but we can do better than that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We filter out all rows where the value in our loaded dataset matches either the NVAL_NUM or TVAL_CHAR value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unmatched_rows = joined_data[(joined_data['value'] != joined_data['TVAL_CHAR']) | (joined_data['value'] != joined_data['NVAL_NUM'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unmatched_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We see that some numeric values loaded are failing to match because they are interpreted as text, so we parse them and filter the matches out of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unmatched_numeric = unmatched_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unmatched_numeric[['value']] = unmatched_numeric[['value']].apply(pandas.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "still_unmatched = unmatched_numeric[(unmatched_numeric['value'] != unmatched_numeric['NVAL_NUM'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As it turns out, some numeric values are in the TVAL_CHAR column, we also parse them and filter out their matches as HPDS automatically converts these for us on load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "still_unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unmatched_char = still_unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unmatched_char = unmatched_char.loc[unmatched_char['TVAL_CHAR'] != 'E']\n",
    "unmatched_char[['TVAL_CHAR']] = unmatched_char[['TVAL_CHAR']].apply(pandas.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unmatched_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "still_unmatched_char = unmatched_char[(unmatched_char['value'] != unmatched_char['TVAL_CHAR'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can now see that all of the discrepancies are explained by the above parsing oddities. This means all our data is in the HPDS datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "still_unmatched_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
